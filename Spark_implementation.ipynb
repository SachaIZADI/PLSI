{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A faire :\n",
    "* Réécrire de manière clean la description de l'algorithme\n",
    "* Travailler sur l'output de l'algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Description of the algorithm (in natural language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach of the article is \"Having computed $q^∗\\left(z;u,s;\\hat{\\theta}\\right)$, we output three (key, value) pairs in the Mapper: $(u, q^∗)$, $(s, q^∗)$, and $(z, q^∗)$.\"\n",
    "\n",
    "In the reduceByKey part however, we can only compute a sum on a couple of variables (e.g. $(u,s)$) and not on a single variable. So we can easily compute $N(z) = \\sum_s\\sum_u q^*(z;u,s)$ but not $N(z,s) = \\sum_u q^*(z;u,s)$ or $\\hat{p}(z,u)=\\frac{\\sum_s q^*(z;u,s)}{\\sum_z\\sum_s q^*(z;u,s)}$ ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize :\n",
    " * document = 2 first columns of the data (remove the headline) --> co-occurences film-user\n",
    " * map ([u,s,z], random)\n",
    "\n",
    "\n",
    "* ([s,z], q*) --> mapper1\n",
    "* ([u,z], q*) --> mapper2\n",
    "\n",
    "* reduceByKey N(z,s) : ([z,s], sum q* du mapper1) \n",
    "* map N(z,s)/N(z) : ([z,s], N(z,s)/sum_s N(z,s))\n",
    "* reduceByKey p(z|u) : ([z,u] sum q^* du mapper 2)\n",
    "* map p(z|u) : ([z,u] p(z|u)/ sum_z p(z|u))\n",
    "\n",
    "* map q(z;u,s) : ([z,u,s], N(z,s)/N(z)$*$p(z|u))\n",
    "* map q(z;u,s) : ([z,u,s], q(z;u,s)/sum_z q(z;u,s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "from numpy import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"ratings.csv\").head(1000).to_csv(\"ratings_short.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Running the 1st iteration of the algorithm step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of 'clusters' is a broadcast variable (useful, but not necessary, when we do the cartesian product)\n",
    "nb_z = sc.broadcast(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = sc.textFile(\"/Users/sachaizadi/Desktop/Projet\\ DataBase\\ Management/Notebooks/ratings_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parser for extracting the interresting information from the dataset.\n",
    "\n",
    "def parseLine(line):\n",
    "    ## Pour l'instant j'ai viré la headline à la mano\n",
    "    ## To Do : virer la headline\n",
    "    line = line.split(',')\n",
    "    line = line[0]+','+line[1]\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a click-log couple (u,s), create a tuple (u,s,z) for z in Z\n",
    "\n",
    "def cartesianProd(us):\n",
    "    to_return = []\n",
    "    for z in range(nb_z.value):\n",
    "        to_return += [us+','+str(z)]\n",
    "    return(to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1,31,0', 0.8306421946730473),\n",
       " ('1,31,1', 0.9679607861144792),\n",
       " ('1,31,2', 0.39185659360881464)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creation of the tuples (u,s,z ; q*)\n",
    "q0 = document.map(parseLine).flatMap(cartesianProd).map(lambda usz : (usz,random.rand()))\n",
    "q0.collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s,z, N(s,z)): \n",
      " [('31,0', 0.43382269053287104)] \n",
      "\n",
      "(z, N(z)): \n",
      " [('0', 516.2809032327694)] \n",
      "\n",
      "(s,z, N(s,z)/N(z)): \n",
      " [('31,0', 0.0008402842092675246)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### ********* M-step (computation of the N(s,z) & N(z) functions) ********\n",
    "\n",
    "# return (s,z, N(s,z))\n",
    "Nsz = q0.map(lambda q : (q[0].split(',')[1]+','+q[0].split(',')[2],q[1])).reduceByKey(lambda x,y : x+y)\n",
    "print('(s,z, N(s,z)): \\n', Nsz.collect()[:1],'\\n')\n",
    "\n",
    "# return (z, N(z)=∑N(s,z))\n",
    "Nz = Nsz.map(lambda N : (N[0].split(',')[1], N[1])).reduceByKey(lambda x,y : x+y)\n",
    "print('(z, N(z)): \\n', Nz.collect()[:1],'\\n')\n",
    "\n",
    "# return (s,z, N(s,z)/N(z))\n",
    "Nsz = Nsz.map(lambda x : (x[0].split(',')[1], (x[0].split(',')[0],x[1]))) #('0', ('31', 0.6602937910124607))\n",
    "tmpN = Nsz.join(Nz) #('0', (('31', 0.6602937910124607), 501.224237413403))\n",
    "Nsz_normalized = tmpN.map(lambda x : (x[1][0][0]+','+x[0], x[1][0][1]/x[1][1]))\n",
    "print('(s,z, N(s,z)/N(z)): \\n', Nsz_normalized.collect()[:1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u,z, p~(z|u)): \n",
      " [('1,1', 10.532771928584513)] \n",
      "\n",
      "(u, ∑p~(z|u)): \n",
      " [('1', 33.75011761937426)] \n",
      "\n",
      "(u,z, p(z|u)): \n",
      " [('4,0', 0.3330270768350648)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### ********* M-step (computation of the p(z|u) function) ********\n",
    "\n",
    "# p~(z|u) is the un-normalized value of p(z|u), i.e. ∑p~(z|u) ≠ 1\n",
    "\n",
    "# return (u,z, p~(z|u))\n",
    "Puz = q0.map(lambda q : (q[0].split(',')[0]+','+q[0].split(',')[2],q[1])).reduceByKey(lambda x,y : x+y)\n",
    "print('(u,z, p~(z|u)): \\n', Puz.collect()[:1],'\\n')\n",
    "\n",
    "# return (u, ∑p~(z|u))\n",
    "Pu = Puz.map(lambda p : (p[0].split(',')[0], p[1])).reduceByKey(lambda x,y : x+y)\n",
    "print('(u, ∑p~(z|u)): \\n', Pu.collect()[:1],'\\n')\n",
    "\n",
    "# return (u, z, p(z|u)=p_(z|u)/∑p_(z|u))\n",
    "Puz = Puz.map(lambda x : (x[0].split(',')[0], (x[0].split(',')[1],x[1]))) #('1', ('1', 9.849132242962598))\n",
    "tmpP = Puz.join(Pu) #('4', (('0', 104.52747209196086), 314.82837141455155))\n",
    "Puz = tmpP.map(lambda x : (x[0]+','+x[1][0][0], x[1][0][1]/x[1][1]))\n",
    "print('(u,z, p(z|u)): \\n', Puz.collect()[:1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u,s;z, N(s,z)/N(z)*p(u|z)): \n",
      " [('9,534,0', 0.00108285749580116)] \n",
      "\n",
      "(u,s, ∑N(s,z)/N(z)*p(u|z)): \n",
      " [('12,608', 0.0019184037277609474)] \n",
      "\n",
      "(u,s;z, q*(u,s;z)): \n",
      " [('10,2827,0', 0.29526173271002115)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### ********* E-step (computation of the q*(u,s;z) function) ********\n",
    "\n",
    "# 1st pre-step: join q0(u,s;z) & p(u|z) on u & z - and forget old value of q*\n",
    "tmpQ0 = q0.map(lambda x : (x[0].split(',')[0]+','+x[0].split(',')[2] , x[0].split(',')[1])) #('4,0', 0.346651199923261)\n",
    "tmpQ0 = tmpQ0.join(Puz) #('9,0', ('1', 0.3019536803179005))\n",
    "\n",
    "# 2nd pre-step: join q0(u,s;z) & N(s,z)/N(z) on s & z\n",
    "tmpQ0 = tmpQ0.map(lambda x : (x[1][0]+','+x[0].split(',')[1] ,\\\n",
    "                             (x[0].split(',')[0],x[1][1]))) #('1,0', ('9', 0.3019536803179005))\n",
    "tmpQ0 = tmpQ0.join(Nsz_normalized) #('534,0', (('9', 0.3019536803179005), 7.06974580116717e-05))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1st step for computing q*(u,s;z) --> return ((u,s;z), N(s,z)/N(z)*p(u|z))\n",
    "# q*~ = N(s,z)/N(z)*p(u|z) is the unormalized version of q* - i.e. ∑q*~ ≠ 1\n",
    "tmpQ0 = tmpQ0.map(lambda x : (x[1][0][0]+','+x[0],\\\n",
    "                             x[1][0][1]*x[1][1]))\n",
    "print('(u,s;z, N(s,z)/N(z)*p(u|z)): \\n', tmpQ0.collect()[:1],'\\n')\n",
    "\n",
    "# 2nd step for computing q*(u,s;z) --> return ((u,s), ∑N(s,z)/N(z)*p(u|z))\n",
    "sumTmpQ0 = tmpQ0.map(lambda x : (x[0].split(',')[0]+','+x[0].split(',')[1],x[1])).reduceByKey(lambda x,y : x+y)\n",
    "print('(u,s, ∑N(s,z)/N(z)*p(u|z)): \\n', sumTmpQ0.collect()[:1],'\\n')\n",
    "\n",
    "\n",
    "# 3rd step for computing q*(u,s;z) --> return ((u,s,z), N(s,z)/N(z)*p(u|z)/{∑N(s,z)/N(z)*p(u|z))}\n",
    "tmpQ0 = tmpQ0.map(lambda x : (x[0].split(',')[0]+','+x[0].split(',')[1],\\\n",
    "                             (x[0].split(',')[2],x[1])))\n",
    "tmpQ0 = tmpQ0.join(sumTmpQ0)\n",
    "q1 = tmpQ0.map(lambda x : (x[0]+','+x[1][0][0], x[1][0][1]/x[1][1]))\n",
    "print('(u,s;z, q*(u,s;z)): \\n', q1.collect()[:1],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Looping through the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parser for extracting the interresting information from the dataset.\n",
    "\n",
    "def parseLine(line):\n",
    "    ## Pour l'instant j'ai viré la headline à la mano\n",
    "    ## To Do : virer la headline\n",
    "    line = line.split(',')\n",
    "    line = line[0]+','+line[1]\n",
    "    return(line)\n",
    "\n",
    "# for a click-log couple (u,s), create a tuple (u,s,z) for z in Z\n",
    "\n",
    "def cartesianProd(us):\n",
    "    to_return = []\n",
    "    for z in range(nb_z.value):\n",
    "        to_return += [us+','+str(z)]\n",
    "    return(to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_z = sc.broadcast(3)\n",
    "nb_iter = 10\n",
    "document = sc.textFile(\"/Users/sachaizadi/Desktop/Projet\\ DataBase\\ Management/Notebooks/ratings_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Initialisation \n",
    "# creation of the tuples (u,s,z ; q*)\n",
    "q = document.map(parseLine).flatMap(cartesianProd).map(lambda usz : (usz,random.rand()))\n",
    "q.collect()[:3]\n",
    "\n",
    "for k in range(nb_iter) :\n",
    "    \n",
    "    # *************************** M-step **************************\n",
    "    # ********* computation of the N(s,z) & N(z) functions *********\n",
    "\n",
    "    # return (s,z, N(s,z))\n",
    "    Nsz = q.map(lambda Q : (Q[0].split(',')[1]+','+Q[0].split(',')[2],Q[1])).reduceByKey(lambda x,y : x+y)\n",
    "\n",
    "    # return (z, N(z)=∑N(s,z))\n",
    "    Nz = Nsz.map(lambda N : (N[0].split(',')[1], N[1])).reduceByKey(lambda x,y : x+y)\n",
    "\n",
    "    # return (s,z, N(s,z)/N(z))\n",
    "    Nsz = Nsz.map(lambda x : (x[0].split(',')[1], (x[0].split(',')[0],x[1])))\n",
    "    tmpN = Nsz.join(Nz)\n",
    "    Nsz_normalized = tmpN.map(lambda x : (x[1][0][0]+','+x[0], x[1][0][1]/x[1][1]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ********* computation of the p(z|u) function *********\n",
    "    # p~(z|u) is the un-normalized value of p(z|u), i.e. ∑p~(z|u) ≠ 1\n",
    "\n",
    "    # return (u,z, p~(z|u))\n",
    "    Puz = q.map(lambda Q : (Q[0].split(',')[0]+','+Q[0].split(',')[2],Q[1])).reduceByKey(lambda x,y : x+y)\n",
    "\n",
    "    # return (u, ∑p~(z|u))\n",
    "    Pu = Puz.map(lambda p : (p[0].split(',')[0], p[1])).reduceByKey(lambda x,y : x+y)\n",
    "\n",
    "    # return (u, z, p(z|u)=p_(z|u)/∑p_(z|u))\n",
    "    Puz = Puz.map(lambda x : (x[0].split(',')[0], (x[0].split(',')[1],x[1])))\n",
    "    tmpP = Puz.join(Pu)\n",
    "    Puz = tmpP.map(lambda x : (x[0]+','+x[1][0][0], x[1][0][1]/x[1][1]))\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    # *************************** E-step **************************\n",
    "    # ********* computation of the q*(u,s;z) function *********\n",
    "\n",
    "    # 1st pre-step: join q(u,s;z) & p(u|z) on u & z - and forget old value of q*\n",
    "    tmpQ = q.map(lambda x : (x[0].split(',')[0]+','+x[0].split(',')[2] , x[0].split(',')[1]))\n",
    "    tmpQ = tmpQ.join(Puz)\n",
    "\n",
    "    # 2nd pre-step: join q0(u,s;z) & N(s,z)/N(z) on s & z\n",
    "    tmpQ = tmpQ.map(lambda x : (x[1][0]+','+x[0].split(',')[1] ,\\\n",
    "                                 (x[0].split(',')[0],x[1][1])))\n",
    "    tmpQ = tmpQ.join(Nsz_normalized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 1st step for computing q*(u,s;z) --> return ((u,s;z), N(s,z)/N(z)*p(u|z))\n",
    "    # q*~ = N(s,z)/N(z)*p(u|z) is the unormalized version of q* - i.e. ∑q*~ ≠ 1\n",
    "    tmpQ = tmpQ.map(lambda x : (x[1][0][0]+','+x[0],\\\n",
    "                                 x[1][0][1]*x[1][1]))\n",
    "\n",
    "    # 2nd step for computing q*(u,s;z) --> return ((u,s), ∑N(s,z)/N(z)*p(u|z))\n",
    "    sumTmpQ = tmpQ.map(lambda x : (x[0].split(',')[0]+','+x[0].split(',')[1],x[1])).reduceByKey(lambda x,y : x+y)\n",
    "\n",
    "    # 3rd step for computing q*(u,s;z) --> return ((u,s,z), N(s,z)/N(z)*p(u|z)/{∑N(s,z)/N(z)*p(u|z))}\n",
    "    tmpQ = tmpQ.map(lambda x : (x[0].split(',')[0]+','+x[0].split(',')[1],\\\n",
    "                                 (x[0].split(',')[2],x[1])))\n",
    "    tmpQ = tmpQ.join(sumTmpQ)\n",
    "    q = tmpQ.map(lambda x : (x[0]+','+x[1][0][0], x[1][0][1]/x[1][1]))\n",
    "    \n",
    "    # we need to collect at this point because otherwise it behaves like a recursive calling which may crash\n",
    "    q = sc.parallelize(q.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
